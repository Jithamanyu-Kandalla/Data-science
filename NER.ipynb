{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "from nltk.chunk import tree2conlltags\n",
        "\n",
        "# Download the 'punkt' and 'averaged_perceptron_tagger' resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') # Download the resource for the PerceptronTagger\n",
        "# Download the 'maxent_ne_chunker' resource\n",
        "nltk.download('maxent_ne_chunker')\n",
        "\n",
        "# Download the 'words' resource\n",
        "nltk.download('words') # Download the 'words' resource\n",
        "\n",
        "# The sentence to analyze\n",
        "sentence = \"Google is planning to open a new office in New York next year.\"\n",
        "\n",
        "def analyze_ner(text):\n",
        "    # Tokenize, POS tag, and perform NER\n",
        "    tokens = word_tokenize(text)\n",
        "    pos_tags = pos_tag(tokens)\n",
        "    ne_tree = ne_chunk(pos_tags)\n",
        "\n",
        "    # Convert tree to IOB format for easier processing\n",
        "    iob_tags = tree2conlltags(ne_tree)\n",
        "    return iob_tags, ne_tree\n",
        "\n",
        "# Perform analysis\n",
        "iob_tags, tree = analyze_ner(sentence)\n",
        "\n",
        "# Entity descriptions\n",
        "entity_descriptions = {\n",
        "    'ORGANIZATION': 'Companies, institutions, agencies, etc.',\n",
        "    'GPE': 'Geo-political entities like cities, states, countries',\n",
        "    'DATE': 'Temporal expressions and dates'\n",
        "}\n",
        "\n",
        "print(\"Named Entity Recognition Analysis:\\n\")\n",
        "print(f\"Original sentence: {sentence}\\n\")\n",
        "print(\"Identified Entities:\")\n",
        "\n",
        "# Process and display results\n",
        "current_entity = []\n",
        "for word, pos, tag in iob_tags:\n",
        "    if tag != 'O':  # O means Outside, not part of named entity\n",
        "        entity_type = tag[2:] if tag.startswith('B-') or tag.startswith('I-') else tag\n",
        "        prefix = tag[0] if tag != 'O' else ''\n",
        "        print(f\"{word:<15} - Tag: {tag:<10} (Entity Type: {entity_type})\")\n",
        "\n",
        "print(\"\\nDetailed Analysis:\")\n",
        "entities = {}\n",
        "current_entity = []\n",
        "for word, pos, tag in iob_tags:\n",
        "    if tag.startswith('B-'):\n",
        "        if current_entity:\n",
        "            entity_type = current_entity[0][2][2:]\n",
        "            entity_text = ' '.join(word for word, _, _ in current_entity)\n",
        "            entities.setdefault(entity_type, []).append(entity_text)\n",
        "        current_entity = [(word, pos, tag)]\n",
        "    elif tag.startswith('I-'):\n",
        "        current_entity.append((word, pos, tag))\n",
        "    else:\n",
        "        if current_entity:\n",
        "            entity_type = current_entity[0][2][2:]\n",
        "            entity_text = ' '.join(word for word, _, _ in current_entity)\n",
        "            entities.setdefault(entity_type, []).append(entity_text)\n",
        "        current_entity = []\n",
        "\n",
        "for entity_type, entity_list in entities.items():\n",
        "    description = entity_descriptions.get(entity_type, \"Other named entity\")\n",
        "    print(f\"\\n{entity_type}:\")\n",
        "    print(f\"  Entities found: {', '.join(entity_list)}\")\n",
        "    print(f\"  Description: {description}\")\n",
        "    print(f\"  Significance: \", end=\"\")\n",
        "    if entity_type == 'ORGANIZATION':\n",
        "        print(\"Identifies the company involved in the action\")\n",
        "    elif entity_type == 'GPE':\n",
        "        print(\"Specifies the location where the action will take place\")\n",
        "    elif entity_type == 'DATE':\n",
        "        print(\"Indicates when the action is planned to occur\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgHGmUq9vHe2",
        "outputId": "0e4ff221-bee8-4f93-b091-d6e94a730d32"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entity Recognition Analysis:\n",
            "\n",
            "Original sentence: Google is planning to open a new office in New York next year.\n",
            "\n",
            "Identified Entities:\n",
            "Google          - Tag: B-GPE      (Entity Type: GPE)\n",
            "New             - Tag: B-GPE      (Entity Type: GPE)\n",
            "York            - Tag: I-GPE      (Entity Type: GPE)\n",
            "\n",
            "Detailed Analysis:\n",
            "\n",
            "GPE:\n",
            "  Entities found: Google, New York\n",
            "  Description: Geo-political entities like cities, states, countries\n",
            "  Significance: Specifies the location where the action will take place\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ]
    }
  ]
}